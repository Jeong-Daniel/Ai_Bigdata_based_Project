{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9f18a0",
   "metadata": {},
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc33e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b96e5",
   "metadata": {},
   "source": [
    "### 데이터 input / 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b80fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    result = []\n",
    "    # sr = 16000이 의미는 1초당 16000개의 데이터를 샘플링\n",
    "    data, sr = librosa.load(path, sr = 16000)\n",
    "    result.append(data)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경 ex) np.array(data, dtype = np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63929b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(data, sr = 16000, n_fft = 256, win_length = 200, hop_length = 160, n_mels = 64):\n",
    "    mel = []\n",
    "    mel_ = librosa.feature.melspectrogram(data, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "    mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref = np.max)\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "910e0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#음성들의 길이를 맞춰줌\n",
    "def set_length(data, d_mini):\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea70aa4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid file: ['.\\\\test_voice.wav']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m voice_path \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./*.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m voice_path \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoice_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m voice_path \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(voice_path)\n\u001b[0;32m      4\u001b[0m mini \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12320\u001b[39m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# sr = 16000이 의미는 1초당 16000개의 데이터를 샘플링\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m data, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m      6\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result) \n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\librosa\\util\\decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     94\u001b[0m ]\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\audio.py:164\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# Otherwise try soundfile first, and then fall back if necessary\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m         y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\librosa\\core\\audio.py:195\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    192\u001b[0m     context \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n\u001b[0;32m    198\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m sf_desc\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\soundfile.py:629\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    628\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\soundfile.py:1182\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     file_ptr \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_open_virtual(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_virtual_io(file),\n\u001b[0;32m   1180\u001b[0m                                     mode_int, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info, _ffi\u001b[38;5;241m.\u001b[39mNULL)\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file: \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1183\u001b[0m _error_check(_snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr),\n\u001b[0;32m   1184\u001b[0m              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid file: ['.\\\\test_voice.wav']"
     ]
    }
   ],
   "source": [
    "voice_path = glob(\"./*.wav\")\n",
    "voice_path = load_data(voice_path)\n",
    "voice_path = np.array(voice_path)\n",
    "mini = 12320\n",
    "voice_path = set_length(voice_path, mini)\n",
    "result = get_feature(voice_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc55f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 78, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#result = result.reshape(result.shape[2], result.shape[1],  -1, 1)\n",
    "result = result.reshape(-1, 64, 78, 1)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c91185f",
   "metadata": {},
   "source": [
    "### 기존 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49b9bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('voice.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df795ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
