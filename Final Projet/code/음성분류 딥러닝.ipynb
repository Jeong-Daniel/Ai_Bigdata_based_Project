{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56b107a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d09a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce028f47",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39538a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_paths = glob(\"./data/원천데이터/test/*/*/*/*.wav\")\n",
    "labels_paths = glob(\"./data/라벨링데이터/test/*/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8c688",
   "metadata": {},
   "source": [
    "### 데이터 전처리\n",
    "librosa 라이브러리를 이용하여 wav파일을 전처리  \n",
    "https://librosa.org/doc/latest/index.html  \n",
    "librosa는 음악 및 오디오 분석용 파이썬 패키지\n",
    "\n",
    "https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html#librosa.feature.melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b61ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(paths):\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        # sr = 16000이 의미는 1초당 16000개의 데이터를 샘플링\n",
    "        data, sr = librosa.load(path, sr = 16000)\n",
    "        result.append(data)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경 ex) np.array(data, dtype = np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "208fb0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(paths):\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        # sr = 16000이 의미는 1초당 16000개의 데이터를 샘플링\n",
    "        with open(path,'r',encoding=\"UTF-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        if json_data['Speaker']['Region']=='00' and json_data['Speaker']['Dialect']=='01':\n",
    "            result.append(0)\n",
    "        elif json_data['Speaker']['Region']=='01':\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(2)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경 ex) np.array(data, dtype = np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70ea6b0",
   "metadata": {},
   "source": [
    "훈련데이터에 대해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d80fc4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133928/133928 [09:22<00:00, 238.24it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_paths = labeling(labels_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06d3f63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cebafb3",
   "metadata": {},
   "source": [
    "데이터프레임으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1472465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(labels_paths, columns = ['type'])\n",
    "dataframe['file_path'] = voice_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d22f9087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_index = dataframe[dataframe['type']==2].index\n",
    "dataframe = dataframe.drop(drop_index)\n",
    "train_y = np.array(dataframe['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d5d2bc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "248ba2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/원천데이터/test\\\\random\\\\2022-01-06\\\\3996\\\\C0691-3996M2111-106000_0-07970327.wav'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe['type']==1]['file_path'].loc[129516]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48bfde0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191759/191759 [42:23<00:00, 75.39it/s]\n"
     ]
    }
   ],
   "source": [
    "dataframevoice_paths = dataframe['file_path']\n",
    "train_x = load_data(dataframevoice_paths)\n",
    "#dataframevoice_paths = load_data(dataframevoice_paths)\n",
    "#np.save(\"./npy_data/train_npy\", dataframevoice_paths)\n",
    "#train_x = dataframevoice_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5f8a4",
   "metadata": {},
   "source": [
    "test 데이터에 대해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce48d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 대회에서 음성은 각각 다른 길이를 가짐\n",
    "# baseline 코드에서는 음성 중 길이가 가장 작은 길이의 데이터를 기준으로 데이터를 잘라서 사용\n",
    "def get_mini(data):\n",
    "    mini = 9999999\n",
    "    for i in data:\n",
    "        if len(i) < mini:\n",
    "            mini = len(i)\n",
    "    return mini\n",
    "\n",
    "#음성들의 길이를 맞춰줌\n",
    "def set_length(data, d_mini):\n",
    "    result = []\n",
    "    for i in data:\n",
    "        result.append(i[:d_mini])\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "#feature를 생성합니다.\n",
    "def get_feature(data, sr = 16000, n_fft = 256, win_length = 200, hop_length = 160, n_mels = 64):\n",
    "    mel = []\n",
    "    for i in tqdm(data):\n",
    "        # win_length 는 음성을 작은 조각으로 자를때 작은 조각의 크기\n",
    "        # hop_length 는 음성을 작은 조각으로 자를때 자르는 간격을 의미\n",
    "        # n_mels 는 적용할 mel filter의 개수\n",
    "        mel_ = librosa.feature.melspectrogram(i, sr = sr, n_fft = n_fft, win_length = win_length, hop_length = hop_length, n_mels = n_mels)\n",
    "        mel.append(mel_)\n",
    "    mel = np.array(mel)\n",
    "    mel = librosa.power_to_db(mel, ref = np.max)\n",
    "    \n",
    "    mel_mean = mel.mean()\n",
    "    mel_std = mel.std()\n",
    "    mel = (mel - mel_mean) / mel_std\n",
    "    \n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af98ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191759/191759 [05:37<00:00, 568.94it/s]\n"
     ]
    }
   ],
   "source": [
    "mini = get_mini(train_x)\n",
    "train_x = set_length(train_x, mini)\n",
    "train_x = get_feature(data = train_x)\n",
    "train_x = train_x.reshape(-1, train_x.shape[1], train_x.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b883ae",
   "metadata": {},
   "source": [
    "### 분석모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a82b7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Convolution2D, BatchNormalization, Flatten,\n",
    "                                     Dropout, Dense, AveragePooling2D, Add)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55fb1aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(input_, units = 32, dropout_rate = 0.5):\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def second_block(input_, units = 64, dropout_rate = 0.5):\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(input_)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Convolution2D(units, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Convolution2D(units, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units, 3, padding =\"same\", activation = \"relu\")(x)\n",
    "    x = Convolution2D(units * 4, 1, padding = \"same\", activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe5e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    dropout_rate = 0.3\n",
    "    \n",
    "    in_ = Input(shape = (train_x.shape[1:]))\n",
    "    \n",
    "    block_01 = block(in_, units = 32, dropout_rate = dropout_rate)\n",
    "    block_02 = block(block_01, units = 64, dropout_rate = dropout_rate)\n",
    "    block_03 = block(block_02, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    block_04 = second_block(block_03, units = 64, dropout_rate = dropout_rate)\n",
    "    block_05 = second_block(block_04, units = 128, dropout_rate = dropout_rate)\n",
    "\n",
    "    x = Flatten()(block_05)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units = 128, activation = \"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Dropout(rate = dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units = 1, activation = 'sigmoid')(x)\n",
    "    model = Model(in_, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3ff898",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bf74c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 10)\n",
    "\n",
    "pred = []\n",
    "pred_ = []\n",
    "\n",
    "for train_idx, val_idx in split.split(train_x, train_y):\n",
    "    x_train, y_train = train_x[train_idx], train_y[train_idx]\n",
    "    x_val, y_val = train_x[val_idx], train_y[val_idx]\n",
    "\n",
    "    model = build_fn()\n",
    "    model.compile(optimizer = keras.optimizers.Adam(0.002),\n",
    "                 loss = keras.losses.BinaryCrossentropy(),\n",
    "                 metrics = ['acc'])\n",
    "    history = model.fit(x = x_train, y = y_train, validation_data = (x_val, y_val), epochs = 8)\n",
    "    model.save('voice.h5')\n",
    "    #print(\"*******************************************************************\")\n",
    "    #pred.append(model.predict(test_x))\n",
    "    #pred_.append(np.argmax(model.predict(test_x), axis = 1))\n",
    "    #print(\"*******************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b3513",
   "metadata": {},
   "source": [
    "### 테스트 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_voice_paths = glob(\"./data/원천데이터/test/*/*/*/*.wav\")\n",
    "test_label_paths = glob(\"./data/라벨링데이터/test/*/*/*/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d455fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_labeling(paths):\n",
    "    result = []\n",
    "    for path in tqdm(paths):\n",
    "        # sr = 16000이 의미는 1초당 16000개의 데이터를 샘플링\n",
    "        with open(path,'r',encoding=\"UTF-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        if json_data['Speaker']['Region']=='00' and json_data['Speaker']['Dialect']=='01':\n",
    "            result.append(0)\n",
    "        elif json_data['Speaker']['Region']=='01'and json_data['Speaker']['Dialect']=='02':\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(2)\n",
    "    result = np.array(result) \n",
    "    # 메모리가 부족할 때는 데이터 타입을 변경 ex) np.array(data, dtype = np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_paths = test_labeling(test_label_paths)\n",
    "dataframe = pd.DataFrame(test_label_paths, columns = ['type'])\n",
    "dataframe['file_path'] = test_voice_paths\n",
    "\n",
    "drop_index = dataframe[dataframe['type']==2].index\n",
    "dataframe = dataframe.drop(drop_index)\n",
    "test_y = np.array(dataframe['type'])\n",
    "\n",
    "test_voice_paths = dataframe['file_path']\n",
    "test_voice_paths = load_data(test_voice_paths)\n",
    "\n",
    "np.save(\"./npy_data/test_npy\", test_voice_paths)\n",
    "test_voice_paths = np.load(\"./npy_data/test_npy.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터 만들기\n",
    "test_x = np.array(test_voice_paths)\n",
    "mini = get_mini(test_x)\n",
    "test_x = set_length(test_x, mini)\n",
    "test_x = get_feature(data = test_x)\n",
    "test_x = test_x.reshape(-1, test_x.shape[1], test_x.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('voice.h5')\n",
    "test_loss, test_acc = new_model.evaluate(test_x,  test_y, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d886a8a",
   "metadata": {},
   "source": [
    "### 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_type(data):\n",
    "    return np.int(data)\n",
    "\n",
    "# 처음에 살펴본 것처럼 glob로 test data의 path는 sample_submission의 id와 같이 1,2,3,4,5.....으로 정렬 되어있지 않음\n",
    "# 만들어둔 test_ 데이터프레임을 이용하여 sample_submission과 predict값의 id를 맞춰줌\n",
    "\n",
    "result = pd.concat([test_, pd.DataFrame(np.mean(pred, axis = 0))], axis = 1).iloc[:, 1:]\n",
    "result[\"id\"] = result[\"id\"].apply(lambda x : cov_type(x))\n",
    "\n",
    "result = pd.merge(sample_submission[\"id\"], result)\n",
    "result.columns = sample_submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7626853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.037994</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>0.023825</td>\n",
       "      <td>0.290019</td>\n",
       "      <td>0.020778</td>\n",
       "      <td>0.620673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.188218</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.535970</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.234284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.157294</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>0.574049</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.198318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.194869</td>\n",
       "      <td>0.067176</td>\n",
       "      <td>0.038670</td>\n",
       "      <td>0.554759</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>0.089171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.207199</td>\n",
       "      <td>0.026973</td>\n",
       "      <td>0.008716</td>\n",
       "      <td>0.332835</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.401787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6095</th>\n",
       "      <td>6096</td>\n",
       "      <td>0.063617</td>\n",
       "      <td>0.053831</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>0.282672</td>\n",
       "      <td>0.241308</td>\n",
       "      <td>0.341721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6096</th>\n",
       "      <td>6097</td>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.324703</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.647963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>6098</td>\n",
       "      <td>0.174698</td>\n",
       "      <td>0.019762</td>\n",
       "      <td>0.012561</td>\n",
       "      <td>0.624443</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.105378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>6099</td>\n",
       "      <td>0.180881</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.359167</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.426683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>6100</td>\n",
       "      <td>0.062526</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>0.010920</td>\n",
       "      <td>0.613567</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>0.258479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    africa  australia    canada   england  hongkong        us\n",
       "0        1  0.037994   0.006710  0.023825  0.290019  0.020778  0.620673\n",
       "1        2  0.188218   0.014532  0.022077  0.535970  0.004920  0.234284\n",
       "2        3  0.157294   0.026830  0.016824  0.574049  0.026685  0.198318\n",
       "3        4  0.194869   0.067176  0.038670  0.554759  0.055354  0.089171\n",
       "4        5  0.207199   0.026973  0.008716  0.332835  0.022489  0.401787\n",
       "...    ...       ...        ...       ...       ...       ...       ...\n",
       "6095  6096  0.063617   0.053831  0.016850  0.282672  0.241308  0.341721\n",
       "6096  6097  0.009056   0.009781  0.004995  0.324703  0.003501  0.647963\n",
       "6097  6098  0.174698   0.019762  0.012561  0.624443  0.063158  0.105378\n",
       "6098  6099  0.180881   0.010444  0.015629  0.359167  0.007196  0.426683\n",
       "6099  6100  0.062526   0.025399  0.010920  0.613567  0.029109  0.258479\n",
       "\n",
       "[6100 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
